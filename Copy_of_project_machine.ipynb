{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of project machine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WesleyHung/comp3359-Emotion-Analysis/blob/master/Copy_of_project_machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmNJdnyhcV37",
        "colab_type": "text"
      },
      "source": [
        "# Comp3359 Project\n",
        "# Emotion Analysis AI machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7135-v0chl4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Listed some styles of our machine here...\n",
        "*   Text classification\n",
        "*   Supervised learning\n",
        "*   LSTM (Type of RNN)\n",
        "*   Attention Mechanism (encoding/ decoding)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8pVocC02yYc",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1HbIW0Ge4oW",
        "colab_type": "code",
        "outputId": "530bc5ce-5df2-4d75-9c8a-185003d597ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify directory of course materials in Google Drive\n",
        "module_dir = '/content/drive/My Drive/'\n",
        "\n",
        "# Path to data file\n",
        "#I put my dataset in my google drive, you can do so by copying from the sharing file\n",
        "data_path = os.path.join(module_dir, 'text_emotion.csv')    \n",
        "  \n",
        "#Loading the dataset into pandas DataFrame\n",
        "data_df = pd.read_csv(data_path)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b58nK2A-gMqV",
        "colab_type": "code",
        "outputId": "5f1f938d-a83e-4dd7-c465-f04d8ab933e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "# Plot label histogram\n",
        "data_df.sentiment.value_counts().plot.bar()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f717f787c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouF2RQ143mps",
        "colab_type": "code",
        "outputId": "7793ec43-44eb-45fb-b3c7-5008d9a75396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "data_df"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>xoshayzers</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>wannamama</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>coolfunky</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>czareaquino</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>xkilljoyx</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>1753918954</td>\n",
              "      <td>neutral</td>\n",
              "      <td>showMe_Heaven</td>\n",
              "      <td>@JohnLloydTaylor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>1753919001</td>\n",
              "      <td>love</td>\n",
              "      <td>drapeaux</td>\n",
              "      <td>Happy Mothers Day  All my love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>1753919005</td>\n",
              "      <td>love</td>\n",
              "      <td>JenniRox</td>\n",
              "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>1753919043</td>\n",
              "      <td>happiness</td>\n",
              "      <td>ipdaman1</td>\n",
              "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>1753919049</td>\n",
              "      <td>love</td>\n",
              "      <td>Alpharalpha</td>\n",
              "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id  ...                                            content\n",
              "0      1956967341  ...  @tiffanylue i know  i was listenin to bad habi...\n",
              "1      1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2      1956967696  ...                Funeral ceremony...gloomy friday...\n",
              "3      1956967789  ...               wants to hang out with friends SOON!\n",
              "4      1956968416  ...  @dannycastillo We want to trade with someone w...\n",
              "...           ...  ...                                                ...\n",
              "39995  1753918954  ...                                   @JohnLloydTaylor\n",
              "39996  1753919001  ...                     Happy Mothers Day  All my love\n",
              "39997  1753919005  ...  Happy Mother's Day to all the mommies out ther...\n",
              "39998  1753919043  ...  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
              "39999  1753919049  ...  @mopedronin bullet train from tokyo    the gf ...\n",
              "\n",
              "[40000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2DdEQbM_Tfm",
        "colab_type": "text"
      },
      "source": [
        "Taking the only useful features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnkObufj_OSr",
        "colab_type": "code",
        "outputId": "323cee9d-d446-4f4a-d122-390d0b95ccf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "data_df = data_df[['sentiment', 'content']]\n",
        "data_df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39995</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@JohnLloydTaylor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>love</td>\n",
              "      <td>Happy Mothers Day  All my love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>love</td>\n",
              "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>happiness</td>\n",
              "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>love</td>\n",
              "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment                                            content\n",
              "0           empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1         sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2         sadness                Funeral ceremony...gloomy friday...\n",
              "3      enthusiasm               wants to hang out with friends SOON!\n",
              "4         neutral  @dannycastillo We want to trade with someone w...\n",
              "...           ...                                                ...\n",
              "39995     neutral                                   @JohnLloydTaylor\n",
              "39996        love                     Happy Mothers Day  All my love\n",
              "39997        love  Happy Mother's Day to all the mommies out ther...\n",
              "39998   happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
              "39999        love  @mopedronin bullet train from tokyo    the gf ...\n",
              "\n",
              "[40000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Mo3Kmi2tIm",
        "colab_type": "text"
      },
      "source": [
        "# Separate Training/Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJuAIRoV3Hkq",
        "colab_type": "text"
      },
      "source": [
        "## Global variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COz5y71e3Kv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random seed for all random process we will use.\n",
        "RAND_SEED = 3359\n",
        "# Size of training dataset (the rest, i.e., 20%,  will be test data)\n",
        "TRAIN_SIZE = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuCmVji3Ov1",
        "colab_type": "text"
      },
      "source": [
        "## Seperate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW6eozgY21ae",
        "colab_type": "code",
        "outputId": "4894c35a-897f-4a47-c57b-b23728f329fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "all_idx = list(range(len(data_df)))\n",
        "\n",
        "# Shuffle the list of indices\n",
        "import random\n",
        "random.seed(RAND_SEED)\n",
        "random.shuffle(all_idx)\n",
        "\n",
        "# Split the random indices into two portion according \n",
        "# to the training size defined\n",
        "p = int(len(data_df) * TRAIN_SIZE)\n",
        "train_idx = all_idx[:p]\n",
        "test_idx = all_idx[p:]\n",
        "\n",
        "# Now, retrieve training/test data records from data_df \n",
        "# according to the indices we prepared in train_idx and test_idx\n",
        "train_df = data_df.iloc[train_idx]\n",
        "test_df = data_df.iloc[test_idx]\n",
        "\n",
        "# However, since the original indices from data_df will be attached to \n",
        "# the retrieved records in train_df and test_df,\n",
        "# we need to reset index so indices in train_df/test_df will start from 0 as usual\n",
        "train_df = train_df.reset_index()\n",
        "test_df = test_df.reset_index()\n",
        "\n",
        "# Drop the automatically created \"index\" column\n",
        "train_df = train_df.drop(['index'], axis=1)\n",
        "test_df = test_df.drop(['index'], axis=1)\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>love</td>\n",
              "      <td>@nomaez hey man, thanks for twitting for twitt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>add me on myspace?? www.myspace.com/pwnage_org...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Almost made it to reading comedy outlet. Headl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@Mira_Brody What is BF ? Is it a glue ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>worry</td>\n",
              "      <td>It appears I'm going home tomorrow...and it's ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0        love  @nomaez hey man, thanks for twitting for twitt...\n",
              "1  enthusiasm  add me on myspace?? www.myspace.com/pwnage_org...\n",
              "2     sadness  Almost made it to reading comedy outlet. Headl...\n",
              "3     neutral            @Mira_Brody What is BF ? Is it a glue ?\n",
              "4       worry  It appears I'm going home tomorrow...and it's ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBgdPBdziF-B",
        "colab_type": "text"
      },
      "source": [
        "# Preprossesing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BMjuHeFiOog",
        "colab_type": "text"
      },
      "source": [
        "## Label the emotions as target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_9xLKNFiK66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = train_df[\"sentiment\"].values.tolist()\n",
        "val_labels = test_df[\"sentiment\"].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ggDCX6ioMr",
        "colab_type": "text"
      },
      "source": [
        "## Creating list of emotions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICTXypj8GHS3",
        "colab_type": "code",
        "outputId": "7acb3ad0-55b8-45e0-dad2-3b0536140f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "label2id = dict()\n",
        "label2id = {l: i for i, l in enumerate(set(labels))}\n",
        "print(label2id)\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "print(id2label)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'boredom': 0, 'anger': 1, 'sadness': 2, 'neutral': 3, 'fun': 4, 'surprise': 5, 'worry': 6, 'empty': 7, 'enthusiasm': 8, 'love': 9, 'relief': 10, 'hate': 11, 'happiness': 12}\n",
            "{0: 'boredom', 1: 'anger', 2: 'sadness', 3: 'neutral', 4: 'fun', 5: 'surprise', 6: 'worry', 7: 'empty', 8: 'enthusiasm', 9: 'love', 10: 'relief', 11: 'hate', 12: 'happiness'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WMbTT_GICmz",
        "colab_type": "text"
      },
      "source": [
        "the following codes are refernce from kaggle, it can be ignored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ry3-qR7irW7",
        "colab_type": "code",
        "outputId": "732469d2-bd4d-410a-9929-7e4283c45b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "# Initialize word2id and label2id dictionaries that will be used to encode words and labels\n",
        "word2id = dict()\n",
        "\n",
        "\n",
        "max_words = 0 # maximum number of words in a sentence\n",
        "\n",
        "# Construction of word2id dict\n",
        "for sentence in input_sentences:\n",
        "    for word in sentence:\n",
        "        # Add words to word2id dict if not exist\n",
        "        if word not in word2id:\n",
        "            word2id[word] = len(word2id)\n",
        "    # If length of the sentence is greater than max_words, update max_words\n",
        "    if len(sentence) > max_words:\n",
        "        max_words = len(sentence)\n",
        "    \n",
        "# Construction of label2id and id2label dicts\n",
        "label2id = {l: i for i, l in enumerate(set(labels))}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "id2word = {v: k for k, v in word2id.items()}\n",
        "id2word\n",
        "\"\"\""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Initialize word2id and label2id dictionaries that will be used to encode words and labels\\nword2id = dict()\\n\\n\\nmax_words = 0 # maximum number of words in a sentence\\n\\n# Construction of word2id dict\\nfor sentence in input_sentences:\\n    for word in sentence:\\n        # Add words to word2id dict if not exist\\n        if word not in word2id:\\n            word2id[word] = len(word2id)\\n    # If length of the sentence is greater than max_words, update max_words\\n    if len(sentence) > max_words:\\n        max_words = len(sentence)\\n    \\n# Construction of label2id and id2label dicts\\nlabel2id = {l: i for i, l in enumerate(set(labels))}\\nid2label = {v: k for k, v in label2id.items()}\\nid2word = {v: k for k, v in word2id.items()}\\nid2word\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O57C_J6kCON",
        "colab_type": "text"
      },
      "source": [
        "# Applying byte pair encoding to word segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVx_Z0K2kAx4",
        "colab_type": "code",
        "outputId": "c5e0b394-30cc-4046-9a8a-6240c52c1fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# we use the folowwing module for word segmentation\n",
        "!pip install subword-nmt\n",
        "\"\"\"\n",
        "bpe_dir = \"/content/drive/My Drive/Colab Notebooks/wmt16_en_de.tar/\"\n",
        "codes = 'bpe.32000'\n",
        "codes_file_path = os.path.join(bpe_dir, codes)\n",
        "\"\"\""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.6/dist-packages (0.3.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZVm0fcImS98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extract the 'content' data as we only need the content to be segmented\n",
        "train_df_content = train_df['content']\n",
        "test_df_content = test_df['content']\n",
        "\n",
        "f_train = open(\"train_content.txt\", \"a\")\n",
        "f_train.write('bpe_content\\n')  # make a name for the data\n",
        "\n",
        "f_test = open(\"test_content.txt\", \"a\")\n",
        "f_test.write('bpe_content\\n')   # make a name for the data\n",
        "\n",
        "for content in train_df_content:\n",
        "  f_train.write(content + '\\n')\n",
        "\n",
        "for content in test_df_content:\n",
        "  f_test.write(content + '\\n')\n",
        "\n",
        "f_train.close()\n",
        "f_test.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMbWtdnel7cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_operations=10000\n",
        "\n",
        "codes_file = '/content/bpe.32000'\n",
        "train_df_content = '/content/train_content.txt'\n",
        "test_df_content = '/content/test_content.txt'\n",
        "\n",
        "bpe_train_df_content = '/content/bpe_train_df_content.txt'\n",
        "bpe_test_df_content = '/content/bpe_test_df_content.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7slelc-loQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start BPE word segmentation\n",
        "!subword-nmt apply-bpe -c {codes_file} < {train_df_content} > {bpe_train_df_content}\n",
        "!subword-nmt apply-bpe -c {codes_file} < {test_df_content} > {bpe_test_df_content}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVgQ-iJL4j1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert .txt format back to .csv format\n",
        "bpe_train_content_df = pd.read_fwf('bpe_train_df_content.txt')\n",
        "#nmu_train_content_df.to_csv('nmu_train_df_content.csv')\n",
        "\n",
        "bpe_test_content_df = pd.read_fwf('bpe_test_df_content.txt')\n",
        "#nmu_test_content_df.to_csv('nmu_test_df_content.csv')\n",
        "\n",
        "\n",
        "#merge them back to dataframe format\n",
        "train_df['bpe_content'] = bpe_train_content_df\n",
        "test_df['bpe_content'] = bpe_test_content_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViA18qzCE8H8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "de537ab4-8dfc-470f-b2c2-bf56ac8615ad"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "      <th>bpe_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>@LeslieCraig haha maybe someday I will be your...</td>\n",
              "      <td>@@@ Les@@ lie@@ Cra@@ ig ha@@ ha maybe som@@ e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>happiness</td>\n",
              "      <td>Skipping school like all the cool kids do</td>\n",
              "      <td>Ski@@ pping school like all the cool kids do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>worry</td>\n",
              "      <td>missing cat makes me sad</td>\n",
              "      <td>missing cat makes me sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@lisamh77 Concord &amp;amp; Irvine, CA only. That'...</td>\n",
              "      <td>@@@ li@@ sam@@ h@@ 77 Con@@ cor@@ d &amp;amp; Ir@@...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>love</td>\n",
              "      <td>@steph1985 Bye  Btw, you like Simple Plan, Hoo...</td>\n",
              "      <td>@@@ st@@ eph@@ 1985 B@@ ye B@@ tw@@ , you like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31995</th>\n",
              "      <td>love</td>\n",
              "      <td>@manoyjoe: thanks. happy mother's day to your ...</td>\n",
              "      <td>@@@ man@@ o@@ y@@ jo@@ e@@ : than@@ ks@@ . hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31996</th>\n",
              "      <td>empty</td>\n",
              "      <td>I jus dropped my dog  and im tall.</td>\n",
              "      <td>I j@@ us dropped my dog and im t@@ all@@ .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31997</th>\n",
              "      <td>love</td>\n",
              "      <td>@gio511 We should have a twitter reunion it wo...</td>\n",
              "      <td>@@@ gi@@ o@@ 5@@ 11 We should have a twi@@ tte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31998</th>\n",
              "      <td>worry</td>\n",
              "      <td>@positron76 You have to come to Chile... with ...</td>\n",
              "      <td>@@@ posi@@ tron@@ 76 You have to come to Chi@@...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31999</th>\n",
              "      <td>fun</td>\n",
              "      <td>@Rick_Tarrant nice! It's mommas day</td>\n",
              "      <td>@@@ R@@ ick@@ _@@ Tar@@ rant ni@@ ce@@ ! It@@ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment  ...                                        bpe_content\n",
              "0      enthusiasm  ...  @@@ Les@@ lie@@ Cra@@ ig ha@@ ha maybe som@@ e...\n",
              "1       happiness  ...       Ski@@ pping school like all the cool kids do\n",
              "2           worry  ...                           missing cat makes me sad\n",
              "3         neutral  ...  @@@ li@@ sam@@ h@@ 77 Con@@ cor@@ d &amp; Ir@@...\n",
              "4            love  ...  @@@ st@@ eph@@ 1985 B@@ ye B@@ tw@@ , you like...\n",
              "...           ...  ...                                                ...\n",
              "31995        love  ...  @@@ man@@ o@@ y@@ jo@@ e@@ : than@@ ks@@ . hap...\n",
              "31996       empty  ...         I j@@ us dropped my dog and im t@@ all@@ .\n",
              "31997        love  ...  @@@ gi@@ o@@ 5@@ 11 We should have a twi@@ tte...\n",
              "31998       worry  ...  @@@ posi@@ tron@@ 76 You have to come to Chi@@...\n",
              "31999         fun  ...  @@@ R@@ ick@@ _@@ Tar@@ rant ni@@ ce@@ ! It@@ ...\n",
              "\n",
              "[32000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdfpPzYqkFAV",
        "colab_type": "text"
      },
      "source": [
        "## Encoding labels with corresponing integer values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfVFsdBWj7OL",
        "colab_type": "code",
        "outputId": "9c222adb-4a58-4eb6-c92f-a5a132949f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#reference to the online material\n",
        "import keras\n",
        "\n",
        "# Encode input words and labels\n",
        "\"\"\"X = [[word2id[word] for word in sentence] for sentence in input_sentences]\"\"\"\n",
        "Y = [label2id[label] for label in labels]\n",
        "val_Y = [label2id[label] for label in val_labels]\n",
        "\n",
        "# Apply Padding to X\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\"\"\"X = pad_sequences(X, max_words)\"\"\"\n",
        "\n",
        "# Convert Y to numpy array\n",
        "Y = keras.utils.to_categorical(Y, num_classes=len(label2id), dtype='float32')\n",
        "val_Y = keras.utils.to_categorical(val_Y, num_classes=len(label2id), dtype='float32')\n",
        "# Print shapes\n",
        "\"\"\"print(\"Shape of X: {}\".format(X.shape))\"\"\"\n",
        "print(\"Shape of Y: {}\".format(Y.shape))\n",
        "print(\"Shape of val_Y: {}\".format(val_Y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Y: (32000, 13)\n",
            "Shape of val_Y: (8000, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoWDUFfS5DvW",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the training dataset and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAcayg230N9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.preprocessing import text\n",
        "\n",
        "# Vectorization parameters\n",
        "# Limit on the number of features. We use the top 20K features.\n",
        "TOP_K = 20000\n",
        "\n",
        "# Limit on the length of text sequences. Sequences longer than this\n",
        "# will be truncated.\n",
        "MAX_SEQUENCE_LENGTH = 500\n",
        "\n",
        "def sequence_vectorize(train_texts, val_texts):\n",
        "    \"\"\"Vectorizes texts as sequence vectors.\n",
        "\n",
        "    1 text = 1 sequence vector with fixed length.\n",
        "\n",
        "    # Arguments\n",
        "        train_texts: list, training text strings.\n",
        "        val_texts: list, validation text strings.\n",
        "\n",
        "    # Returns\n",
        "        x_train, x_val, word_index: vectorized training and validation\n",
        "            texts and word index dictionary.\n",
        "    \"\"\"\n",
        "    # Create vocabulary with training texts.\n",
        "    tokenizer = text.Tokenizer(num_words=TOP_K)\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "    # Vectorize training and validation texts.\n",
        "    x_train = tokenizer.texts_to_sequences(train_texts)\n",
        "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "    # Get max sequence length.\n",
        "    max_length = len(max(x_train, key=len))\n",
        "    \n",
        "    if max_length > MAX_SEQUENCE_LENGTH:\n",
        "      max_length = MAX_SEQUENCE_LENGTH\n",
        "    \n",
        "    # Fix sequence length to max value. Sequences shorter than the length are\n",
        "    # padded in the beginning and sequences longer are truncated\n",
        "    # at the beginning.\n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
        "    return x_train, x_val, tokenizer.word_index, max_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjO_UdV_1Wi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val, word_index, max_words = sequence_vectorize(train_df['content'], test_df['content'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GGEhMigkfJ-",
        "colab_type": "text"
      },
      "source": [
        "# Build LSTM model with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ExrvW5kV-B",
        "colab_type": "code",
        "outputId": "9f242f3f-c134-4bcc-ce96-f6ec1f0a5b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "embedding_dim = 100 # The dimension of word embeddings\n",
        "\n",
        "# Define input tensor\n",
        "sequence_input = keras.Input(shape=(max_words,), dtype='int32')\n",
        "\n",
        "# Word embedding layer\n",
        "embedded_inputs =keras.layers.Embedding(len(train) + 1,\n",
        "                                        embedding_dim,\n",
        "                                        input_length=max_words)(sequence_input)\n",
        "\n",
        "# Apply dropout to prevent overfitting\n",
        "embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n",
        "\n",
        "# Apply Bidirectional LSTM over embedded inputs\n",
        "lstm_outs = keras.layers.wrappers.Bidirectional(\n",
        "    keras.layers.LSTM(embedding_dim, return_sequences=True)\n",
        ")(embedded_inputs)\n",
        "\n",
        "# Apply dropout to LSTM outputs to prevent overfitting\n",
        "lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n",
        "\n",
        "# Attention Mechanism - Generate attention vectors\n",
        "input_dim = int(lstm_outs.shape[2])\n",
        "permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n",
        "attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n",
        "attention_vector = keras.layers.Reshape((max_words,))(attention_vector)\n",
        "attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n",
        "attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n",
        "\n",
        "# Last layer: fully connected with softmax activation\n",
        "fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n",
        "output = keras.layers.Dense(len(label2id), activation='softmax')(fc)\n",
        "\n",
        "# Finally building model\n",
        "model = keras.Model(inputs=[sequence_input], outputs=output)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 35, 100)      3200100     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 35, 100)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 35, 200)      160800      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 35, 200)      0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 35, 1)        201         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 35)           0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_vec (Activation)      (None, 35)           0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n",
            "                                                                 attention_vec[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 13)           1313        dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,382,514\n",
            "Trainable params: 3,382,514\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUfXvL2pnfHS",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNb5YFxkkRK",
        "colab_type": "code",
        "outputId": "f0212080-a208-4990-b22a-64c81cc0f06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "# Train model 10 iterations\n",
        "model.fit(train, Y, epochs=10, batch_size=64, validation_split=0.1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 28800 samples, validate on 3200 samples\n",
            "Epoch 1/10\n",
            "28800/28800 [==============================] - 62s 2ms/step - loss: 2.0874 - accuracy: 0.2742 - val_loss: 1.9252 - val_accuracy: 0.3291\n",
            "Epoch 2/10\n",
            "28800/28800 [==============================] - 61s 2ms/step - loss: 1.8330 - accuracy: 0.3820 - val_loss: 1.8866 - val_accuracy: 0.3525\n",
            "Epoch 3/10\n",
            "28800/28800 [==============================] - 61s 2ms/step - loss: 1.6528 - accuracy: 0.4477 - val_loss: 1.9635 - val_accuracy: 0.3413\n",
            "Epoch 4/10\n",
            "28800/28800 [==============================] - 60s 2ms/step - loss: 1.4543 - accuracy: 0.5247 - val_loss: 2.0802 - val_accuracy: 0.3187\n",
            "Epoch 5/10\n",
            "28800/28800 [==============================] - 61s 2ms/step - loss: 1.2563 - accuracy: 0.5944 - val_loss: 2.2940 - val_accuracy: 0.3075\n",
            "Epoch 6/10\n",
            "28800/28800 [==============================] - 61s 2ms/step - loss: 1.0782 - accuracy: 0.6525 - val_loss: 2.6620 - val_accuracy: 0.2962\n",
            "Epoch 7/10\n",
            "28800/28800 [==============================] - 60s 2ms/step - loss: 0.9294 - accuracy: 0.6998 - val_loss: 2.8681 - val_accuracy: 0.2847\n",
            "Epoch 8/10\n",
            "28800/28800 [==============================] - 61s 2ms/step - loss: 0.8155 - accuracy: 0.7336 - val_loss: 3.2147 - val_accuracy: 0.2869\n",
            "Epoch 9/10\n",
            "28800/28800 [==============================] - 61s 2ms/step - loss: 0.7296 - accuracy: 0.7627 - val_loss: 3.3311 - val_accuracy: 0.2831\n",
            "Epoch 10/10\n",
            "28800/28800 [==============================] - 60s 2ms/step - loss: 0.6675 - accuracy: 0.7810 - val_loss: 3.5871 - val_accuracy: 0.2753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f394d25f8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VArlUvPJoYvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "mdoel_save_name = \"lstm_attention_v1_trained.h5\" \n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu_BMhnI8S0F",
        "colab_type": "text"
      },
      "source": [
        "If you want to use the existing model, I've already store it in our shared file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdTqk5uo8ewb",
        "colab_type": "code",
        "outputId": "50d17a98-1413-430f-d1cc-2599bdeb520d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "\"\"\"\n",
        "!pip install gdown==3.6.0\n",
        "\n",
        "my_file_id = \"1M1VxKSiCgecAkogInyEwc4Phx3b9PzbF\"\n",
        "!gdown https://drive.google.com/uc?id={my_file_id}\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gdown==3.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/12/33/e9f21d0b3f85804ca570d124fb7a80c12a99948ff495cf54dfb72f18bf9e/gdown-3.6.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (2020.4.5.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.6.0-cp36-none-any.whl size=5238 sha256=862dcbb3adcfd348dbc5f8ed3eb9be2f216a3a1071059fcf994634c6f65685c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/90/fa/25654eb65da3e6da7752db71a164e0eb8f7a6fb4335eeb46ab\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed gdown-3.6.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1M1VxKSiCgecAkogInyEwc4Phx3b9PzbF\n",
            "To: /content/lstm_attention_v1_trained.h5\n",
            "40.6MB [00:00, 74.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fifFMdTeTnm5",
        "colab_type": "code",
        "outputId": "3a349e67-5e01-484b-ca51-d978a584a772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\"\"\"\n",
        "import keras\n",
        "model_from_drive = keras.models.load_model('lstm_attention_v1_trained.h5')\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGgy_PKwpAS4",
        "colab_type": "text"
      },
      "source": [
        "# Testing and predicting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q040otVlL3NW",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdqvpVkpL_XK",
        "colab_type": "code",
        "outputId": "f5fa8141-2edd-41c6-8ce6-38a936029a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Create a new model instance\n",
        "#If you using the loaded model, uncomment this line:\n",
        "#model = model_from_drive\n",
        "\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(val, val_Y, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored model, accuracy: 10.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMcgDbNUL5lF",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llOQveJzoZWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-create the model to get attention vectors as well as label prediction\n",
        "model_with_attentions = keras.Model(inputs=model.input,\n",
        "                                    outputs=[model.output, \n",
        "                                             model.get_layer('attention_vec').output])\n",
        "\n",
        "\"\"\"\n",
        "# If you just use the downloaded model wothout trained yourself, please use here:\n",
        "model_with_attentions = keras.Model(inputs=model_from_drive.input,\n",
        "                                    outputs=[model_from_drive.output, \n",
        "                                             model_from_drive.get_layer('attention_vec').output])\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DxnB2dEoa59",
        "colab_type": "code",
        "outputId": "22b55830-7bd0-4088-96d6-2804d6ed09e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "# Select random samples to illustrate\n",
        "sample_text = \"fuck\"\n",
        "sample_text = sample_text.lower()\n",
        "#sample_text = random.choice(val)\n",
        "\n",
        "\n",
        "# Encode samples\n",
        "tokenized_sample = sample_text.split(\" \")\n",
        "encoded_samples = [[word_index[word] for word in tokenized_sample]]\n",
        "\n",
        "# Padding\n",
        "encoded_samples = keras.preprocessing.sequence.pad_sequences(encoded_samples, maxlen=max_words)\n",
        "\n",
        "#encoded_samples = sample_text\n",
        "#print(encoded_samples.shape)\n",
        "# Make predictions\n",
        "label_probs, attentions = model_with_attentions.predict(encoded_samples)\n",
        "label_probs = {id2label[_id]: prob for (label, _id), prob in zip(label2id.items(),label_probs[0])}\n",
        "\n",
        "# Get word attentions using attenion vector\n",
        "token_attention_dic = {}\n",
        "max_score = 0.0\n",
        "min_score = 0.0\n",
        "for token, attention_score in zip(tokenized_sample, attentions[0][-len(tokenized_sample):]):\n",
        "    token_attention_dic[token] = math.sqrt(attention_score)\n",
        "\n",
        "\n",
        "# VISUALIZATION\n",
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def rgb_to_hex(rgb):\n",
        "    return '#%02x%02x%02x' % rgb\n",
        "    \n",
        "def attention2color(attention_score):\n",
        "    r = 255 - int(attention_score * 255)\n",
        "    color = rgb_to_hex((255, r, r))\n",
        "    return str(color)\n",
        "    \n",
        "# Build HTML String to viualize attentions\n",
        "html_text = \"<hr><p style='font-size: large'><b>Text:  </b>\"\n",
        "for token, attention in token_attention_dic.items():\n",
        "    html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention),\n",
        "                                                                        token)\n",
        "html_text += \"</p>\"\n",
        "# Display text enriched with attention scores \n",
        "display(HTML(html_text))\n",
        "\n",
        "# PLOT EMOTION SCORES\n",
        "emotions = [label for label, _ in label_probs.items()]\n",
        "scores = [score for _, score in label_probs.items()]\n",
        "plt.figure(figsize=(5,2))\n",
        "plt.bar(np.arange(len(emotions)), scores, align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan', \"purple\"])\n",
        "plt.xticks(np.arange(len(emotions)), emotions)\n",
        "plt.ylabel('Scores')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ff3b3b;'>fuck <span> </p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 500x200 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn_KAqDW-ee3",
        "colab_type": "text"
      },
      "source": [
        "In case the above chart is hard to see, here is the list of proboabilities showing the likeliness of emotions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l928yZAof8T",
        "colab_type": "code",
        "outputId": "5d3475b3-1868-401e-d2d7-9b6dd62e0f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import operator\n",
        "\n",
        "# create a list of emotion in decending order of their probability \n",
        "emotion_list=[]\n",
        "\n",
        "for  _, emotion in enumerate(label_probs):\n",
        "    temp = [emotion, label_probs[emotion]]\n",
        "    emotion_list.append(temp)\n",
        "\n",
        "sorted(emotion_list, key=operator.itemgetter(1), reverse= True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['sadness', 0.26072118],\n",
              " ['boredom', 0.22221008],\n",
              " ['enthusiasm', 0.19029243],\n",
              " ['love', 0.12629803],\n",
              " ['surprise', 0.0747112],\n",
              " ['happiness', 0.04855724],\n",
              " ['fun', 0.03365236],\n",
              " ['empty', 0.015033543],\n",
              " ['relief', 0.013303055],\n",
              " ['hate', 0.0050725946],\n",
              " ['neutral', 0.0038676239],\n",
              " ['anger', 0.0033641763],\n",
              " ['worry', 0.002916514]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx5FMi7FG6Pd",
        "colab_type": "text"
      },
      "source": [
        "# Serveral gusses of improving the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV5q1KtrHA3f",
        "colab_type": "text"
      },
      "source": [
        "*   half the data with labels of many dataset\n",
        "*   cut out the label with too few dataset\n",
        "*   using sub-wording tokenization\n",
        "*   (List item)\n",
        "\n"
      ]
    }
  ]
}